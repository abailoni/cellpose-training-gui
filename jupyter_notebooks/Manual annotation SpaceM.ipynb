{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "*General tip 1*: Whenever you modify anything in this notebook, do not forget to click on the save button. In this way, all changes will be saved and you will be able to continue working on your project later on.\n",
    "\n",
    "*General tip 2*: To run a part of this notebook, you should first click on a section/cell (after selecting it, you should see a blue bar on the left side) and then click the Play button above (alternatively, press *Shift+Enter*). After running a cell, the next one will be automatically selected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial imports\n",
    "The following code-cell loads the packages that will be used by the notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from segmfriends.io.images import read_uint8_img\n",
    "import napari\n",
    "from magicgui import magicgui\n",
    "from napari.types import ImageData, LabelsData, ShapesData\n",
    "from napari.layers import Shapes\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import Button\n",
    "from tkinter import Tk, filedialog\n",
    "from IPython.display import clear_output, display\n",
    "from IPython.display import Markdown, Latex\n",
    "import imageio\n",
    "\n",
    "from annotationtools.base_experiment import BaseAnnotationExperiment\n",
    "from annotationtools.io import file_dialog, dir_dialog\n",
    "from annotationtools.notebook_utils.widgets_utils import SelectImagePath, display_proj_dir_browse_button"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select a project directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/run-cells-in-section.jpg\" alt=\"run-cells-in-section\" width=\"50%\" style=\"float:right; margin-left: 10%;\"/>\n",
    "\n",
    "\n",
    "**Important**: \n",
    "\n",
    "-  If not done already, please set the *project_directory* variable in code-cell below.\n",
    "- **Make sure to run all the cells in this section** every time you run the notebook. To do so, you can also right-click on the Table–of-Contents list on the left side (see screenshot on the side)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FAQ**:\n",
    "- **What is the project directory?** The project directory is the folder that will contain all the data and images generated by this notebook. If you are starting a new labeling project, then create and select an empty folder: all generated annotations will be saved in that folder. Otherwise, select the path to a project you have been previously worked on.\n",
    "- **How do I set the project path?** You can either enter it manually or you can use the \"Browse...\" button below to get the path of any directory on your machine. After that, do not forget to copy the obtained path in the code cell below where the *project_directory* variable is defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hide_input": true,
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b293539ae08549abab4b7367aeecad8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Text(value='', layout=Layout(width='60%'), placeholder='Path to project directory (to be copied…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display \"Browse\" button to select project directory:\n",
    "display_proj_dir_browse_button()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --------------------  TO BE FILLED BY USER - Start  -----------------------------\n",
    "# Insert path to project directory:\n",
    "project_directory = \"/Users/alberto-mac/EMBL_ATeam/cellpose_training_pipeline/test_project\" \n",
    "# ---------------------  TO BE FILLED BY USER - End  ------------------------------\n",
    "\n",
    "# Load the annotation project:\n",
    "annotation_exp = BaseAnnotationExperiment(project_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Images in your project\n",
    "By running the code cell below you will see the list of images that are already part of your project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hide_input": true,
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Name loaded project:** '*test_project*' \n",
       "\n",
       "There are 1 images loaded in the project:\n",
       "    \n",
       "- Image 1:\n",
       "    - Path main image: */Users/alberto-mac/EMBL_ATeam/cellpose_training_pipeline/test_images/img1/fused_tp_0_ch_4.tif*\n",
       "    - Number of selected regions of interest in image: *3*  \n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show images in project:\n",
    "\n",
    "input_images_with_nb_rois = annotation_exp.get_list_rois_per_image()\n",
    "echo = f\"\"\"**Name loaded project:** '*{os.path.split(project_directory)[1]}*' \n",
    "\n",
    "\"\"\"\n",
    "nb_images = len(input_images_with_nb_rois)\n",
    "if nb_images:\n",
    "    echo += f\"\"\"There are {nb_images} images loaded in the project:\n",
    "    \"\"\"\n",
    "else:\n",
    "    echo += f\"\"\"There are no images loaded in the project.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "for i, in_image in enumerate(input_images_with_nb_rois):\n",
    "    echo += f\"\"\"\n",
    "- Image {i+1}:\n",
    "    - Path main image: *{in_image[0]}*\n",
    "    - Number of selected regions of interest in image: *{in_image[1]}*  \n",
    "    \"\"\"\n",
    "    \n",
    "display(Markdown(echo))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add a new image/dataset to the project\n",
    "**Important:** If the image you want is already in the project, you don't need to fill the fields shown in this section and you can directly move on to the next section.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "Use the fields below to add an additional image to the project:\n",
       "- **Main channel**: select the path of the main channel that should be segmented (usually the bright-field channel)\n",
       "- **DAPI channel**: If you have it, please provide it because it can be very useful for getting a better segmentation\n",
       "- **Additional channels**: If you have additional channels that may helpful for the manual annotation process, you can load two extra ones. \n",
       "- **How to specify image paths:**\n",
       "    - *Option 1*: Specify all channel paths manually\n",
       "    - *Option 2*: If all channel images are in the same directory and have similar names, e.g. *img_ch0.tif*, *img_ch1.tif*, *img_ch2.tif*, \n",
       "you only need to provide the filename filters (*_ch0*, *_ch1*, *_ch2*, ...) and the paths of the additional channels\n",
       "will be automatically deduced from the main-channel image.\n",
       "- When you have specified all the paths, press on the submit button *\"Add image to project\"*. \n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e01390fc8434879aa2f109a210af1bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Label(value='', layout=Layout(width='20px')), Label(value='Channel name:', layou…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from annotationtools.notebook_utils.add_proj_image import AddNewImageToProject\n",
    "add_new_image = AddNewImageToProject(annotation_exp)\n",
    "add_new_image.display_notebook_widgets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select regions of interest to be annotated\n",
    "In this section, you will load an image and then select one or more region of interests (rectangular boxes) that you will manually annotate in the following and will be used to train the segmentation algorithm. \n",
    "\n",
    "## Things to keep in mind when selecting regions of interest\n",
    "- When you select a region of interest, keep in mind that **you will need to manually annotate all cells inside that region of interest**. Each region of interest should contain **at least several dozens of cells, ideally ~100**.\n",
    "- These region of interests will be used to train the segmentation algorithm, so you should select the most representative parts of your data. If there are some particularly challenging parts of your data the you would like the segmentation algorithm to properly segment, then you should also select some regions of interest from these difficult parts. \n",
    "\n",
    "Here you have some example scenarios:\n",
    "1. Your images/datasets present several artifacts close to the borders, but you only care to have an accurate segmentation in the central part of the image, where image quality is higher and there are no artifacts. In this case, you can select regions of interest only from the central area of your image.\n",
    "2. Your images/datasets present several artifacts in all parts of the image, and you would like cells to be properly segmented even in parts of the image where these artifacts are present. Then, you should also include regions of interest where some of the artifacts are visible (on top of region of interests that are easier to segment)\n",
    "3. You acquired several images that look somehow different (different acquisition method, brightness, etc). Then, you should evenly select regions of interest across all your images/datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select the image you want to work with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hide_input": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec4fb4746ab3402686901f7817d2fc30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Select an image in the project: '), Dropdown(layout=Layout(width='90%'), options=(…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "input_images_with_nb_rois = annotation_exp.get_list_rois_per_image()\n",
    "\n",
    "dropdown_widget = widgets.Dropdown(\n",
    "    options=[(img_data[0], i)  for i, img_data in enumerate(input_images_with_nb_rois)],\n",
    "    value=0,\n",
    "    disabled=False,\n",
    "    layout=widgets.Layout(width='90%')\n",
    ")\n",
    "\n",
    "id_selected_image = 0\n",
    "\n",
    "def on_dropdown_value_change(change):\n",
    "    global id_selected_image\n",
    "    id_selected_image = change['new']\n",
    "\n",
    "dropdown_widget.observe(on_dropdown_value_change, names='value')\n",
    "\n",
    "image_choice_widgets = widgets.VBox([widgets.Label(value=\"Select an image in the project: \"), dropdown_widget])\n",
    "display(image_choice_widgets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modify / create regions of interest in Napari\n",
    "After you run the next cell, the selected image will be loaded in Napari. \n",
    "\n",
    "Then select the \"Rectangle\" tool in napari to draw one or more region of interests.\n",
    "\n",
    "After you are done, close the Napari window and run the  the next sections \n",
    "\n",
    "- Select, move, and delete boxes\n",
    "- Insert image of Napari viewer? (Showing the various buttons)\n",
    "\n",
    "<!-- ![Napari](./napari-screenshot.jpg) -->\n",
    "\n",
    "Run the following cell to start napari:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffa14a51ab804b3dadcdae0cef7aa347",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Label(value='Select an image in the project: '), Dropdown(layout=Layout(width='9…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from annotationtools.notebook_utils.create_rois import CreateROIs\n",
    "create_roi = CreateROIs(annotation_exp)\n",
    "create_roi.display_widgets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROIs image 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<napari._qt.widgets.qt_viewer_dock_widget.QtViewerDockWidget at 0x7fa13c92b1f0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assert id_selected_image is not None\n",
    "\n",
    "image_paths = annotation_exp.get_image_paths(id_selected_image)\n",
    "\n",
    "# create the viewer and display the image\n",
    "viewer = napari.Viewer()\n",
    "\n",
    "channel_colormaps = [\"gray\", \"red\", \"yellow\", \"cyan\"]\n",
    "for i, channel in enumerate(image_paths):\n",
    "    viewer.add_image(read_uint8_img(image_paths[channel])[...,0], name=channel, colormap=channel_colormaps[i],\n",
    "                    blending='additive')\n",
    "\n",
    "napari_rois = annotation_exp.get_napari_roi_by_image_id(id_selected_image)\n",
    "    \n",
    "# Load images in napari:\n",
    "s_layer = viewer.add_shapes(data=napari_rois, name=\"ROIs image {}\".format(id_selected_image), shape_type=\"rectangle\", opacity=0.15,  edge_color='#fff01dff', face_color='#f9ffbeff')\n",
    "\n",
    "\n",
    "@magicgui(\n",
    "    call_button=\"Save regions of interest\",\n",
    "    shapes={'label': 'ROIs layer:'\n",
    "           },\n",
    ")\n",
    "def save_ROIs(shapes: Shapes): \n",
    "    id_image = int(shapes.name.split(\" \")[2])\n",
    "    print(id_image)\n",
    "    if len(shapes.data):\n",
    "        annotation_exp.update_rois_image(id_image, shapes.data)\n",
    "\n",
    "viewer.window.add_dock_widget(save_ROIs, area='right')  # Add our gui instance to napari viewer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell when you are done selecting the ROIs in napari:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: add event to napari and call this every time a ROI is updated:\n",
    "# print(napari_rois.shape)\n",
    "\n",
    "ROIs_data = s_layer.data\n",
    "if len(ROIs_data):\n",
    "    annotation_exp.update_rois_image(id_selected_image, ROIs_data)\n",
    "else:\n",
    "    print(\"No ROIs found for selected image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manual annotation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12a88dfa629d4f86a6a271e59cf587de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Select ROI to annotate: '), Dropdown(layout=Layout(width='90%'), options=(('Image …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rois_list = annotation_exp.get_roi_list()\n",
    "\n",
    "dropdown_image_to_annotate = widgets.Dropdown(\n",
    "    options=[(\"Image {} - Region of interest {} - {}\".format(roi_info['image_id']+1, roi_info['roi_index_per_image']+1,\n",
    "                                                          \"(has labels)\" if roi_info['has_label'] else \"(DOES NOT HAVE LABELS)\"), \n",
    "              roi_info['roi_id'])  \n",
    "             for roi_info in rois_list],\n",
    "    disabled=False,\n",
    "    layout=widgets.Layout(width='90%')\n",
    ")\n",
    "\n",
    "id_roi_to_annotate = rois_list[0]['roi_id']\n",
    "\n",
    "def on_image_to_annotate_value_change(change):\n",
    "    global id_roi_to_annotate\n",
    "    id_roi_to_annotate = change['new']\n",
    "\n",
    "dropdown_image_to_annotate.observe(on_image_to_annotate_value_change, names='value')\n",
    "\n",
    "image_choice_widgets = widgets.VBox([widgets.Label(value=\"Select ROI to annotate: \"), dropdown_image_to_annotate])\n",
    "display(image_choice_widgets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "uint8\n"
     ]
    }
   ],
   "source": [
    "assert id_roi_to_annotate is not None\n",
    "\n",
    "print(id_roi_to_annotate)\n",
    "roi_paths = annotation_exp.get_training_image_paths(id_roi_to_annotate)\n",
    "\n",
    "# create the viewer and display the image\n",
    "viewer = napari.Viewer()\n",
    "\n",
    "composite_image = read_uint8_img(roi_paths[\"composite_image\"])\n",
    "\n",
    "# composite_image = img = imageio.imread(roi_paths[\"composite_image\"])\n",
    "# print(roi_paths[\"composite_image\"], composite_image.shape)\n",
    "# assert np.allclose(composite_image[...,0], composite_image[...,1])\n",
    "# for channel in reversed(roi_paths[\"single_channels\"]):\n",
    "#     viewer.add_image(read_uint8_img(roi_paths[\"single_channels\"][channel]), name=channel)\n",
    "viewer.add_image(composite_image, \n",
    "                 name=[channel for channel in roi_paths[\"single_channels\"]], \n",
    "                 colormap = [\"gray\", \"red\", \"yellow\", \"cyan\"],\n",
    "                 channel_axis=2)\n",
    "    \n",
    "\n",
    "annotations = imageio.imread(roi_paths[\"label_image\"]) if roi_paths[\"has_labels\"] else np.zeros(shape=composite_image.shape[:2], dtype='uint16')\n",
    "    \n",
    "# Load images in napari:\n",
    "labels_layer = viewer.add_labels(annotations, name='Annotations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_exp.update_roi_labels(id_roi_to_annotate, labels_layer.data.astype('uint16'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "TODO: copy actual labels left in project in another training folder (some may have been deleted)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc-autonumbering": true,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
