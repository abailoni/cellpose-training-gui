{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "*General tip 1*: Whenever you modify anything in this notebook, do not forget to click on the save button. In this way, all changes will be saved and you will be able to continue working on your project later on.\n",
    "\n",
    "*General tip 2*: To run a part of this notebook, you should first click on a section/cell (after selecting it, you should see a blue bar on the left side) and then click the Play button above (alternatively, press *Shift+Enter*). After running a cell, the next one will be automatically selected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select project directory\n",
    "- If you are starting a new labeling project, select an empty folder: all generated data and labels will be saved in this folder.\n",
    "- If you want to keep working with an exhisting project, then select the previous project folder: data in the project will be automatically loaded.\n",
    "\n",
    "To get the path of the selected project directory, you can click on the \"Browse...\" button below. Then you will be able to copy the displayed path in the code-cell below (see comments below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from segmfriends.io.images import read_uint8_img\n",
    "import napari\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import Button\n",
    "from tkinter import Tk, filedialog\n",
    "from IPython.display import clear_output, display\n",
    "from IPython.display import Markdown, Latex\n",
    "import imageio\n",
    "\n",
    "from annotationtools.io import file_dialog, dir_dialog\n",
    "from annotationtools.notebook_utils.widgets import SelectImagePath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "hide_input": true,
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "- If not done already, please set the *project_directory* variable in the next code-cell with the full path of the project directory.\n",
       "- Optionally, you can use the field below to get the path of a directory on your machine. \n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d02fdab0d2d449c4bf3c811647f48f99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Label(value='Select a project directory: '), Button(description='Browse...', sty…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create button to select project directory:\n",
    "\n",
    "selected_directory_1 = widgets.Label(value=\"\")\n",
    "selected_directory_2 = widgets.Label(value=\"\")\n",
    "\n",
    "def select_proj_dir(b):\n",
    "    dir_path = dir_dialog.gui_fname()\n",
    "    selected_directory_1.value = \"Copy the following path of the project directory in the code cell below:\"\n",
    "    selected_directory_2.value = dir_path\n",
    "\n",
    "\n",
    "fileselect = Button(description=\"Browse...\")\n",
    "fileselect.on_click(select_proj_dir)\n",
    "\n",
    "display(Markdown(\"\"\"\n",
    "- If not done already, please set the *project_directory* variable in the next code-cell\n",
    "- Optionally, you can use the field below to get the path of a directory on your machine. \n",
    "\"\"\"))\n",
    "\n",
    "widgets.VBox(\n",
    "    [widgets.HBox([widgets.Label(value=\"Select a project directory: \"), fileselect]), \n",
    "     selected_directory_1,\n",
    "     selected_directory_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Do not forget to re-run this cell and the following one every time you change any path\n",
    "\n",
    "# --------------------  TO BE FILLED BY USER - START  -----------------------------\n",
    "\n",
    "# Insert path to project directory here:\n",
    "project_directory = \"/Users/alberto-mac/EMBL_ATeam/cellpose_training_pipeline/test_project\" \n",
    "\n",
    "# ---------------------  TO BE FILLED BY USER - END  ------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "hide_input": true,
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Name loaded project:** '*test_project*' \n",
       "\n",
       "There are 1 images loaded in the project:\n",
       "    \n",
       "- Image 1:\n",
       "    - Path main image: */Users/alberto-mac/EMBL_ATeam/cellpose_training_pipeline/test_images/img1/fused_tp_0_ch_4.tif*\n",
       "    - Number of selected regions of interest in image: *2*  \n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from annotationtools.base_experiment import BaseAnnotationExperiment\n",
    "annotation_exp = BaseAnnotationExperiment(project_directory)\n",
    "\n",
    "input_images_with_nb_rois = annotation_exp.get_list_rois_per_image()\n",
    "echo = f\"\"\"**Name loaded project:** '*{os.path.split(project_directory)[1]}*' \n",
    "\n",
    "\"\"\"\n",
    "nb_images = len(input_images_with_nb_rois)\n",
    "if nb_images:\n",
    "    echo += f\"\"\"There are {nb_images} images loaded in the project:\n",
    "    \"\"\"\n",
    "else:\n",
    "    echo += f\"\"\"There are no images loaded in the project.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "for i, in_image in enumerate(input_images_with_nb_rois):\n",
    "    echo += f\"\"\"\n",
    "- Image {i+1}:\n",
    "    - Path main image: *{in_image[0]}*\n",
    "    - Number of selected regions of interest in image: *{in_image[1]}*  \n",
    "    \"\"\"\n",
    "    \n",
    "display(Markdown(echo))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add a new image/dataset to the project\n",
    "**Important:** If the image you want to work with was already added to the project, then you can skip this section and move on to section 3.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "Use the fields below to add an additional image to the project:\n",
       "- **Main channel**: select the path of the main channel that should be segmented (usually the bright-field channel)\n",
       "- **DAPI channel**: If you have it, please provide it because it can be very useful for getting a better segmentation\n",
       "- **Additional channels**: If you have additional channels that may helpful for the manual annotation process, you can load two extra ones. \n",
       "- **How to specify image paths:**\n",
       "    - *Option 1*: Specify all channel paths manually\n",
       "    - *Option 2*: If all channel images are in the same directory and have similar names, e.g. *img_ch0.tif*, *img_ch1.tif*, *img_ch2.tif*, \n",
       "you only need to provide the filename filters *_ch0*, *_ch1*, *_ch2*. The full paths of the additional image channels\n",
       "will be automatically deduced from the main-channel image.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5661e8921d4a4580a2e888e238cd7beb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Label(value='', layout=Layout(width='20px')), Label(value='Channel name:', layou…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from annotationtools.notebook_utils.widgets import display_new_image_widgets\n",
    "display_new_image_widgets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------  TO BE FILLED BY USER - START  -----------------------------\n",
    "\n",
    "# Main image to be segmented:\n",
    "main_image_path = \"/Users/alberto-mac/EMBL_ATeam/cellpose_training_pipeline/test_images/img1/fused_tp_0_ch_4.tif\"\n",
    "\n",
    "use_dapi_channel_for_segmentation = True\n",
    "\n",
    "# For additional (optional) channels, you can either specify the image paths...\n",
    "dapi_image_path = \"\"\n",
    "extra_ch_1_image_path = \"\"\n",
    "extra_ch_2_image_path = \"\"\n",
    "\n",
    "# ...or you can define some name filters, so that additional channels are automatically found in the same\n",
    "# directory of the main image:\n",
    "filter_main_image = \"_ch_4\"\n",
    "filter_dapi_image = \"_ch_2\"\n",
    "filter_extra_ch_1 = \"_ch_1\"\n",
    "filter_extra_ch_2 = \"\"\n",
    "\n",
    "# If you want, you can also define the extra channel names, for clarity:\n",
    "extra_ch_1_name = \"GFP\"\n",
    "extra_ch_2_name = \"Extra channel 2\"\n",
    "\n",
    "# ---------------------  TO BE FILLED BY USER - END  ------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "hide_input": true,
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The added image was already present in the project. Updating paths.\n"
     ]
    }
   ],
   "source": [
    "# Add new image to experiment:\n",
    "\n",
    "# TODO: add check and only execute if paths were given! (User may fill option 1 and then execute this code!)\n",
    "\n",
    "annotation_exp.use_dapi_channel_for_segmentation = use_dapi_channel_for_segmentation\n",
    "annotation_exp.set_extra_channels_names([extra_ch_1_name, extra_ch_2_name])\n",
    "id_selected_image = annotation_exp.add_input_image(main_image_path,\n",
    "                               filter_main_image,\n",
    "                               dapi_image_path,\n",
    "                               filter_dapi_image,\n",
    "                               extra_ch_1_image_path,\n",
    "                               filter_extra_ch_1,\n",
    "                               extra_ch_2_image_path,\n",
    "                               filter_extra_ch_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'/Users/alberto-mac/EMBL_repos/manual_annotation_spacem/jupyter_notebooks/first_test.ipynb'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "file_dialog.gui_fname()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select regions of interest to be annotated\n",
    "In this section, you will load an image and then select one or more region of interests (rectangular boxes) that you will manually annotate in the following and will be used to train the segmentation algorithm. \n",
    "\n",
    "## Things to keep in mind when selecting regions of interest\n",
    "- When you select a region of interest, keep in mind that **you will need to manually annotate all cells inside that region of interest**. Each region of interest should contain **at least several dozens of cells, ideally ~100**.\n",
    "- These region of interests will be used to train the segmentation algorithm, so you should select the most representative parts of your data. If there are some particularly challenging parts of your data the you would like the segmentation algorithm to properly segment, then you should also select some regions of interest from these difficult parts. \n",
    "\n",
    "Here you have some example scenarios:\n",
    "1. Your images/datasets present several artifacts close to the borders, but you only care to have an accurate segmentation in the central part of the image, where image quality is higher and there are no artifacts. In this case, you can select regions of interest only from the central area of your image.\n",
    "2. Your images/datasets present several artifacts in all parts of the image, and you would like cells to be properly segmented even in parts of the image where these artifacts are present. Then, you should also include regions of interest where some of the artifacts are visible (on top of region of interests that are easier to segment)\n",
    "3. You acquired several images that look somehow different (different acquisition method, brightness, etc). Then, you should evenly select regions of interest across all your images/datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select the image you want to work with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "hide_input": true,
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3cb799d4d7646248fbd23d9594345a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Select an image in the project: '), Dropdown(layout=Layout(width='90%'), options=(…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "input_images_with_nb_rois = annotation_exp.get_list_rois_per_image()\n",
    "\n",
    "dropdown_widget = widgets.Dropdown(\n",
    "    options=[(img_data[0], i)  for i, img_data in enumerate(input_images_with_nb_rois)],\n",
    "    value=0,\n",
    "    disabled=False,\n",
    "    layout=widgets.Layout(width='90%')\n",
    ")\n",
    "\n",
    "id_selected_image = 0\n",
    "\n",
    "def on_dropdown_value_change(change):\n",
    "    global id_selected_image\n",
    "    id_selected_image = change['new']\n",
    "\n",
    "dropdown_widget.observe(on_dropdown_value_change, names='value')\n",
    "\n",
    "image_choice_widgets = widgets.VBox([widgets.Label(value=\"Select an image in the project: \"), dropdown_widget])\n",
    "display(image_choice_widgets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modify / create regions of interest in Napari\n",
    "After you run the next cell, the selected image will be loaded in Napari. \n",
    "\n",
    "Then select the \"Rectangle\" tool in napari to draw one or more region of interests.\n",
    "\n",
    "After you are done, close the Napari window and run the  the next sections \n",
    "\n",
    "- Select, move, and delete boxes\n",
    "- Insert image of Napari viewer? (Showing the various buttons)\n",
    "\n",
    "<!-- ![Napari](./napari-screenshot.jpg) -->\n",
    "\n",
    "Run the following cell to start napari:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "assert id_selected_image is not None\n",
    "\n",
    "image_paths = annotation_exp.get_image_paths(id_selected_image)\n",
    "\n",
    "# create the viewer and display the image\n",
    "viewer = napari.Viewer()\n",
    "\n",
    "channel_colormaps = [\"gray\", \"red\", \"yellow\", \"cyan\"]\n",
    "for i, channel in enumerate(image_paths):\n",
    "    viewer.add_image(read_uint8_img(image_paths[channel])[...,0], name=channel, colormap=channel_colormaps[i],\n",
    "                    blending='additive')\n",
    "\n",
    "napari_rois = annotation_exp.get_napari_roi_by_image_id(id_selected_image)\n",
    "    \n",
    "# Load images in napari:\n",
    "s_layer = viewer.add_shapes(data=napari_rois, name=\"Crops\", shape_type=\"rectangle\", opacity=0.15,  edge_color='#fff01dff', face_color='#f9ffbeff')\n",
    "# draw some rectangles, then inspect\n",
    "# s_layer.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell when you are done selecting the ROIs in napari:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: add event to napari and call this every time a ROI is updated:\n",
    "# print(napari_rois.shape)\n",
    "\n",
    "ROIs_data = s_layer.data\n",
    "if len(ROIs_data):\n",
    "    annotation_exp.update_rois_image(id_selected_image, ROIs_data)\n",
    "else:\n",
    "    print(\"No ROIs found for selected image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manual annotation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12a88dfa629d4f86a6a271e59cf587de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Select ROI to annotate: '), Dropdown(layout=Layout(width='90%'), options=(('Image …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rois_list = annotation_exp.get_roi_list()\n",
    "\n",
    "dropdown_image_to_annotate = widgets.Dropdown(\n",
    "    options=[(\"Image {} - Region of interest {} - {}\".format(roi_info['image_id']+1, roi_info['roi_index_per_image']+1,\n",
    "                                                          \"(has labels)\" if roi_info['has_label'] else \"(DOES NOT HAVE LABELS)\"), \n",
    "              roi_info['roi_id'])  \n",
    "             for roi_info in rois_list],\n",
    "    disabled=False,\n",
    "    layout=widgets.Layout(width='90%')\n",
    ")\n",
    "\n",
    "id_roi_to_annotate = rois_list[0]['roi_id']\n",
    "\n",
    "def on_image_to_annotate_value_change(change):\n",
    "    global id_roi_to_annotate\n",
    "    id_roi_to_annotate = change['new']\n",
    "\n",
    "dropdown_image_to_annotate.observe(on_image_to_annotate_value_change, names='value')\n",
    "\n",
    "image_choice_widgets = widgets.VBox([widgets.Label(value=\"Select ROI to annotate: \"), dropdown_image_to_annotate])\n",
    "display(image_choice_widgets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "uint8\n"
     ]
    }
   ],
   "source": [
    "assert id_roi_to_annotate is not None\n",
    "\n",
    "print(id_roi_to_annotate)\n",
    "roi_paths = annotation_exp.get_training_image_paths(id_roi_to_annotate)\n",
    "\n",
    "# create the viewer and display the image\n",
    "viewer = napari.Viewer()\n",
    "\n",
    "composite_image = read_uint8_img(roi_paths[\"composite_image\"])\n",
    "\n",
    "# composite_image = img = imageio.imread(roi_paths[\"composite_image\"])\n",
    "# print(roi_paths[\"composite_image\"], composite_image.shape)\n",
    "# assert np.allclose(composite_image[...,0], composite_image[...,1])\n",
    "# for channel in reversed(roi_paths[\"single_channels\"]):\n",
    "#     viewer.add_image(read_uint8_img(roi_paths[\"single_channels\"][channel]), name=channel)\n",
    "viewer.add_image(composite_image, \n",
    "                 name=[channel for channel in roi_paths[\"single_channels\"]], \n",
    "                 colormap = [\"gray\", \"red\", \"yellow\", \"cyan\"],\n",
    "                 channel_axis=2)\n",
    "    \n",
    "\n",
    "annotations = imageio.imread(roi_paths[\"label_image\"]) if roi_paths[\"has_labels\"] else np.zeros(shape=composite_image.shape[:2], dtype='uint16')\n",
    "    \n",
    "# Load images in napari:\n",
    "labels_layer = viewer.add_labels(annotations, name='Annotations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_exp.update_roi_labels(id_roi_to_annotate, labels_layer.data.astype('uint16'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "TODO: copy actual labels left in project in another training folder (some may have been deleted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "518d98ae724f40dd94abfa0d639ceddc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(IntSlider(value=0, description='a'), IntSlider(value=0, description='b'), IntSli…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "global a1\n",
    "a = widgets.IntSlider(description='a')\n",
    "b = widgets.IntSlider(description='b')\n",
    "c = widgets.IntSlider(description='c')\n",
    "\n",
    "\n",
    "def f(a, b, c):\n",
    "    print('{}*{}*{}={}'.format(a, b, c, a * b * c))\n",
    "\n",
    "\n",
    "out = widgets.interactive_output(f, {'a': a, 'b': b, 'c': c})\n",
    "\n",
    "widgets.HBox([widgets.VBox([a, b, c]), out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_main = widgets.Text(\n",
    "    value='',\n",
    "    placeholder='Enter directory path',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "widgets.HBox([widgets.VBox([a, b, c]), out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "print(a.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31de198250f84492bc87284814ed1ba8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='The selected .')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d597ec7ac1d4c7983d8fb2830d95434",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=1, description='Slider', max=5, min=-5)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "caption = widgets.Label(value='The selected .')\n",
    "slider = widgets.IntSlider(min=-5, max=5, value=1, description='Slider')\n",
    "\n",
    "\n",
    "def handle_slider_change(change):\n",
    "    caption.value = 'The slider value is ' + (\n",
    "        'negative' if change.new < 0 else 'nonnegative'\n",
    "    )\n",
    "\n",
    "\n",
    "slider.observe(handle_slider_change, names='value')\n",
    "\n",
    "display(caption, slider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21e3b17dbde84a0c919a00f18fd7e8c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c95084c699244899c343b0ed409e5eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "int_range = widgets.IntSlider()\n",
    "output2 = widgets.Output()\n",
    "\n",
    "display(int_range, output2)\n",
    "\n",
    "\n",
    "def on_value_change(change):\n",
    "    with output2:\n",
    "        print(change['new'])\n",
    "\n",
    "\n",
    "int_range.observe(on_value_change, names='value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc-autonumbering": true,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
